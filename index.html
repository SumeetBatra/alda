<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ALDA is a method that learns a disentangled latent representation and performs association to enable zero-shot generalization for vision-based RL agents.">
  <meta name="keywords" content="disentangled representation learning, associative memory, reinforcement learning, robotics, DMControl, generalization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ALDA: Associative Latent DisentAnglement</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ALDA: Associative Latent DisentAnglement</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sumeetbatra.github.io/">Sumeet Batra</a>,</span>
            <span class="author-block">
              <a href="https://viterbi.usc.edu/directory/faculty/Sukhatme/Gaurav">Gaurav Sukhatme</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of Southern California</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2410.07441"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.07441"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Generalizing vision-based reinforcement learning (RL) agents to novel environments remains a difficult and open challenge. 
          Current trends are to collect large-scale datasets or use data augmentation techniques to prevent overfitting and improve downstream generalization. 
          However, the computational and data collection costs increase exponentially with the number of task variations and can destabilize the already difficult task of training RL agents. 
          In this work, we take inspiration from recent advances in computational neuroscience and propose a model, Associative Latent DisentAnglement (ALDA), that builds on standard off-policy RL towards zero-shot generalization. 
          Specifically, we revisit the role of latent disentanglement in RL and show how combining it with a model of associative memory achieves zero-shot generalization on difficult task variations without relying on data augmentation. 
          Finally, we formally show that data augmentation techniques are a form of weak disentanglement and discuss the implications of this insight. Code coming soon!
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered">
        <div class="column">
          <video id="teaser-left" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/walker/alda_walker_walk_train.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column">
          <video id="teaser-center" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/walker/alda_walker_walk_color_hard.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column">
          <video id="teaser-right" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/walker/alda_walker_walk_distracting_cs.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">ALDA</span> trains only on the original, unmodified task without data augmentation (left) and acheives strong zero-shot generalization performance
        on challenging distribution shifts (center and right).
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-8">
        <figure class="image-figure large-figure">
          <img src="./static/images/associate.png" alt="Diagram of disentanglement and association">
          <figcaption class="has-text-centered">
            ALDA has two main components. First, it learns a disentangled representation of the latent variables that produce the observations. 
            Second, it uses an associative memory mechanism to zero-shot map individual latent variables to in-distribution values when presented with OOD observations.
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">



    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Latent Traversals</h2>
        <figure class="image-figure">
          <img src="./static/images/color_perturb.png" alt="Latent traversals">
          <figcaption class="has-text-centered">
            Latent traversals of ALDA trained directly on the "color hard" environment for the Walker task. The colors of the agent, floor, and sky are randomly changed to extreme RGB values on reset. 
          </figcaption>
        </figure>
        <p>
          <br>
          We can visualize the efffects of a disentangled latent representation. We do this by interpolating one latent dimension while keeping the others fixed, 
          and visualize the resulting latent codes by passing them through a decoder. 
          ALDA learns to factorize background or "distractor" variables from task relevant variables automatically. 
          From the latent traversals on the "color hard" environment, we see that latent dimensions that interpolate aspects of the agent (legs, torso, feet) do not affect color information 
          of the agent (or sky and floor) and vice versa. 
          <br>
          <br>
        </p>
        
      
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Latent Trajectories</h2>
          <p>
            An interesting property of ALDA is that the latent variable trajectories through time oscillate with similar patterns as the some of the agent's proprioceptive state variables. 
            We visualize a few of the latent variable trajectories and compare them with some of the agent's proprioceptive state trajectories for a single rollout. 
            Given that the ALDA learns a disentangled latent representation, it highly likely that some of the latent variables correspond to certain proprioceptive state variables, such as 
            joint angles through time. 
            While the mapping from high dimensional image observation to the latent space is arbitrary and need not 1:1 correspond with proprioceptive state variables, this remains an 
            interesting observation that merits further investigation.
            <br>
            <br>
          </p>
          <figure class="image-figure">
            <img src="./static/images/latent_state_trajs.png" alt="Latent and state trajectories">
          </figure>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Experiments</h2>
          <figure class="image-figure">
            <img src="./static/images/main_plots.png" alt="Main results">
          </figure>
          <p>
            We compare against a set of baselines that together cover the range of approaches to zero-shot generalization in vision-based RL, including learning task-centric representations (RePo), 
            disentangled representation learning without association (DARLA), and data augmentation (SVEA). 
            We train on four tasks from the DMControl suite and test on two distribution shift environments, "color hard" that randomizes the colors of the scene and "DistractingCS" which
            introduces camera perturbations and plays a video in the background. 
            ALDA performs better than all baselines on all tasks except SVEA, which uses additional data during data augmentation that likely puts the training distribution inside the support of the test distributions
            induced by the evaluation environments. 
          </p>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Videos</h2>
          <h2 class="title is-4">Cartpole Balance</h2>
          <div class="columns is-centered">
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/cartpole/alda_cartpole_balance_train.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Original Task</p>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/cartpole/alda_cartpole_balance_color_hard.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Color Hard</p>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/cartpole/alda_cartpole_balance_distracting_cs.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Distracting CS</p>
            </div>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4">Finger Spin</h2>
          <div class="columns is-centered">
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/finger spin/alda_finger_spin_train.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Original Task</p>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/finger spin/alda_finger_spin_color_hard.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Color Hard</p>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/finger spin/alda_finger_spin_distracting_cs.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Distracting CS</p>
            </div>
          </div>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4">Ball in Cup Catch</h2>
          <div class="columns is-centered">
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/ball in cup catch/alda_ball_in_cup_catch_train.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Original Task</p>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/ball in cup catch/alda_ball_in_cup_catch_color_hard.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Color Hard</p>
            </div>
            <div class="column">
              <video autoplay muted loop playsinline height="100%">
                <source src="./static/videos/ball in cup catch/alda_ball_in_cup_catch_distracting_cs.mp4" type="video/mp4">
              </video>
              <p class="has-text-centered">Distracting CS</p>
            </div>
          </div>
        </div>
      </div>




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template borrowed from <a href="https://nerfies.github.io/">Nerfies</a> under a <a rel="license"
            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
